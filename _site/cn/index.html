<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin SEO -->





<title>Wanjun Zhong (é’Ÿå®›å›) - Homepage</title>







<meta property="og:locale" content="en">
<meta property="og:site_name" content="Wanjun Zhong (é’Ÿå®›å›)">
<meta property="og:title" content="Wanjun Zhong (é’Ÿå®›å›)">


  <link rel="canonical" href="http://0.0.0.0:4000/cn/">
  <meta property="og:url" content="http://0.0.0.0:4000/cn/">



  <meta property="og:description" content="Senior Research Scientist at ByteDance Seed, focusing on Large Language Models, Reasoning towards AGI, and Agent Framework.">









<!-- end SEO -->


<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
<head>
  <base target="_blank">
</head>
    <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
<link rel="manifest" href="/images/site.webmanifest">

<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    <div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg masthead__menu-home-item"><a href="#about-me">Homepage</a></li>
          
            <li class="masthead__menu-item"><a href="/#about-me">About Me</a></li>
          
            <li class="masthead__menu-item"><a href="/#-news">News</a></li>
          
            <li class="masthead__menu-item"><a href="/#-publications">Publications</a></li>
          
            <li class="masthead__menu-item"><a href="/#-honors-and-awards">Honors and Awards</a></li>
          
            <li class="masthead__menu-item"><a href="/#-educations">Educations</a></li>
          
            <li class="masthead__menu-item"><a href="/#-invited-talks">Invited Talks</a></li>
          
            <li class="masthead__menu-item"><a href="/#-internships">Internships</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    <div id="main" role="main">
      
  <div class="sidebar sticky">
  

<div itemscope itemtype="http://schema.org/Person" class="profile_box">

  <div class="author__avatar">
    <img src="images/wanjun_profile.jpg" class="author__avatar" alt="Wanjun Zhong (é’Ÿå®›å›)">
  </div>

  <div class="author__content">
    <h3 class="author__name">Wanjun Zhong (é’Ÿå®›å›)</h3>
    <p class="author__bio">ByteDance Seed</p>
  </div>

  <div class="author__urls-wrapper">
    <!-- <button class="btn btn--inverse">More Info & Contact</button> -->
    <ul class="author__urls social-icons">
      
        <li><div style="white-space: normal; margin-bottom: 1em;">Senior Research Scientist at ByteDance Seed, focusing on Large Language Models, Reasoning towards AGI, and Agent Framework.</div></li>
      
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> China</li>
      
      
      
      
        <li><a href="mailto:wanjun@bytedance.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://github.com/zhongwanjun"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=FGIZfyQAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
      
      
      
    </ul>
      <div class="author__urls_sm">
      
      
        <a href="mailto:wanjun@bytedance.com"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i></a>
      
      
       
      
      
      
      
      
      
      
      
      
      
        <a href="https://github.com/zhongwanjun"><i class="fab fa-fw fa-github" aria-hidden="true"></i></a>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <a href="https://scholar.google.com/citations?user=FGIZfyQAAAAJ"><i class="fas fa-fw fa-graduation-cap"></i></a>
      
      
      
      
      
    </div>
  </div>
</div>

  
  </div>

    
      <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
        <meta itemprop="headline" content="">
        <div class="page__inner-wrap">
          <section class="page__content" itemprop="text">
            <div class="language-switch">
  <a href="/" class="lang-btn">English</a>
  <a href="/cn/" class="lang-btn active">ä¸­æ–‡</a>
</div>

<p><span class="anchor" id="about-me"></span></p>

<div class="content-section intro-section">
# è‡ªæˆ‘ä»‹ç»

**é’Ÿå®›å›** || zhongwj25@mail2.sysu.edu.cn || https://zhongwanjun.github.io || (+86) 13609749192

æˆ‘ç›®å‰åœ¨å­—èŠ‚è·³åŠ¨Seedå›¢é˜Ÿæ‹…ä»»ç ”ç©¶å‘˜ï¼Œå‚ä¸TopSeedäººæ‰è®¡åˆ’ã€‚
æˆ‘çš„ç ”ç©¶æ–¹å‘ä¸“æ³¨äºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¤æ‚æ¨ç†èƒ½åŠ›å’ŒAgentåŸºåº§æ¨¡å‹ã€‚
æˆ‘ä»¬æ­£åœ¨æ‹›è˜**ç ”ç©¶å®ä¹ ç”Ÿ**å¹¶å¯»æ±‚**å­¦æœ¯åˆä½œ**ï¼Œæ¬¢è¿éšæ—¶è”ç³»æˆ‘ï¼š[wanjun@bytedance.com](mailto:wanjun@bytedance.com)

åœ¨æ­¤ä¹‹å‰ï¼Œæˆ‘æ›¾åœ¨[åä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤](http://dev3.noahlab.com.hk/)æ‹…ä»»é«˜çº§ç ”ç©¶å‘˜ï¼Œå‚ä¸åä¸ºå¤©æ‰å°‘å¹´è®¡åˆ’ã€‚
æˆ‘æ›¾äº2018è‡³2023å¹´æœŸé—´ï¼Œå‚ä¸ä¸­å±±å¤§å­¦ä¸å¾®è½¯äºšæ´²ç ”ç©¶é™¢ï¼ˆMSRAï¼‰[è”åˆåŸ¹å…»åšå£«é¡¹ç›®](https://www.msra.cn/zh-cn/connections/academic-programs/joint-phd)ï¼Œå¹¶åœ¨[ä¸­å±±å¤§å­¦](http://www.sysu.edu.cn/en/index.htm)[è®¡ç®—æœºç§‘å­¦ä¸å·¥ç¨‹å­¦é™¢](http://sdcs.sysu.edu.cn/)è·å¾—åšå£«å­¦ä½ã€‚

ä½œä¸ºè”åˆåŸ¹å…»åšå£«ç”Ÿï¼Œæˆ‘çš„å¯¼å¸ˆåŒ…æ‹¬[å‘¨æ˜åšå£«](https://scholar.google.co.jp/citations?user=a0w5c0gAAAAJ&amp;hl=en)ã€[å°é‰´æ•™æˆ](http://sdcs.sysu.edu.cn/content/2505)å’Œ[ç‹ç”²æµ·æ•™æˆ](http://sdcs.sysu.edu.cn/content/2551)ã€‚æˆ‘æ›¾åœ¨MSRAè‡ªç„¶è¯­è¨€è®¡ç®—ç»„å®ä¹ ï¼Œå¯¼å¸ˆä¸º[æ®µæ¥ åšå£«](https://nanduan.github.io/)ã€‚

æˆ‘äº2021å¹´è·å¾—[å¾®è½¯å­¦è€…å¥–å­¦é‡‘](https://www.microsoft.com/en-us/research/academic-program/phd-fellowship/#!people)ï¼ˆæ¯å¹´äºšå¤ªåœ°åŒº11åæ°å‡ºåšå£«ç”Ÿï¼‰ï¼Œå¹¶äº2023å¹´å…¥é€‰[åä¸ºå¤©æ‰å°‘å¹´è®¡åˆ’](https://career.huawei.com/reccampportal/portal5/topminds.html)åŠACMå¹¿å·ä¼˜ç§€åšå£«è®ºæ–‡å¥–ã€‚

æˆ‘æ›¾åœ¨é¡¶çº§AIä¼šè®®å’ŒæœŸåˆŠä¸Šå‘è¡¨äº†40å¤šç¯‡è®ºæ–‡ï¼ŒåŒ…æ‹¬NeurIPSã€ICLRã€ACLã€EMNLPã€TASLPã€NAACLã€AAAIã€IJCAIã€ISSTAç­‰ã€‚

## æˆ‘çš„ç ”ç©¶å…´è¶£
- **å¤§è¯­è¨€æ¨¡å‹**
- **é¢å‘AGIçš„æ¨ç†**
- **AgentåŸºåº§æ¨¡å‹**

# å·¥ä½œåŠæ•™è‚²ç»å†
- **å­—èŠ‚è·³åŠ¨Seed Edgeå›¢é˜Ÿ - å¤§æ¨¡å‹é«˜çº§ç ”ç©¶å‘˜**
    - **æ—¶é—´**ï¼šJune 2024 â€“ Now
    - **èŒè´£**ï¼šå¤§è¯­è¨€æ¨¡å‹å’ŒAgentæ–¹å‘é«˜çº§ç ”ç©¶å‘˜ï¼Œ
    - **é¡¹ç›®ç»å†**ï¼š
      - è±†åŒ…çº¿ä¸Šç”¨æˆ·æ•°æ®é£è½®
      - Seed-Thinkingé•¿æ€ç»´é“¾æ¨ç†æ¨¡å‹ï¼š
      - Seed-AgentåŸºåº§æ¨¡å‹ï¼š
        - UI-TARS ï¼ˆä¸šç•Œå¼€æºçš„GUI+Game AgentåŸºåº§æ¨¡å‹ï¼‰çš„è®­ç»ƒ
        - ReTool (Agentå¤šè½®å·¥å…·è°ƒç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¡†æ¶)
        - MCPå·¥å…·å¢å¼ºçš„DeepReseachæ¨¡å‹åŠé€šç”¨AgentåŸºåº§æ¨¡å‹è®­ç»ƒ
- **åä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤ - è¯­éŸ³è¯­ä¹‰å®éªŒå®¤ - ç ”ç©¶å‘˜ï¼ˆå¤©æ‰å°‘å¹´ï¼‰**
    - **æ—¶é—´**ï¼šJune 2023 â€“ June 2024
    - **é¡¹ç›®ç»å†**ï¼šå¤§è¯­è¨€æ¨¡å‹æ–¹å‘ç ”ç©¶å‘˜ï¼Œä¸“é—¨è´Ÿè´£ç›˜å¤åŸºç¡€è¯­è¨€æ¨¡å‹æŒ‡ä»¤å¾®è°ƒã€æ•°æ®é£è½®ã€Agentè¶…çº§å¯¹é½å’Œå¤æ‚æ¨ç†ç­‰ç ”ç©¶å’Œè½åœ°ã€‚
- **å¾®è½¯äºšæ´²ç ”ç©¶é™¢ - è”åˆåŸ¹å…»é¡¹ç›®é•¿æœŸå®ä¹ **
    - **æ—¶é—´**ï¼šJune 2018 â€“ June 2023 

### æ•™è‚²èƒŒæ™¯
- **ä¸­å±±å¤§å­¦ Sun Yat-Sen University (SYSU) - å¾®è½¯äºšæ´²ç ”ç©¶é™¢ï¼ˆMSRAï¼‰è”åˆåŸ¹å…»åšå£«ç”Ÿé¡¹ç›®**
    - **æ—¶é—´**ï¼šSep 2018 â€“ June 2023
    - **å­¦ä½åŠä¸“ä¸š**ï¼šè®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ä¸“ä¸šç›´æ¥æ”»è¯»åšå£«å­¦ä½ç ”ç©¶ç”Ÿ
    - **æŒ‡å¯¼å¯¼å¸ˆ**ï¼šå‘¨æ˜åšå£«ï¼ˆæ¾œèˆŸç§‘æŠ€CEOï¼Œå‰MSRAå‰¯é™¢é•¿ï¼‰ï¼Œå°é‰´æ•™æˆï¼ˆä¸­å±±å¤§å­¦ï¼‰ï¼Œç‹ç”²æµ·æ•™æˆï¼ˆä¸­å±±å¤§å­¦ï¼‰
- **ä¸­å±±å¤§å­¦ Sun Yat-Sen University (SYSU)**
    - **æ—¶é—´**ï¼šSep 2014 â€“ June 2018
    - **å­¦é™¢åŠä¸“ä¸š**ï¼šæ•°æ®ç§‘å­¦ä¸è®¡ç®—æœºå­¦é™¢ï¼Œè½¯ä»¶å·¥ç¨‹ä¸“ä¸šå­¦å£« 
  
# è£èª‰&amp;å¥–é¡¹
## å­¦æœ¯ç«èµ›
- **CVPR - Ego4D Challenge for Episodic Memory Natural Language Queries**ï¼šå† å†›ï¼ˆ2023 å¹´ï¼‰
- **ECCV - Ego4D Challenge for Episodic Memory Natural Language Queries**ï¼šå­£å†›ï¼ˆ2022 å¹´ï¼‰
- **å…¨çƒï¼ˆå—äº¬ï¼‰äººå·¥æ™ºèƒ½åº”ç”¨å¤§èµ›**ï¼šä¼˜èƒœå¥–ï¼ˆ2018 å¹´ï¼‰
- **å›½å®¶å¤§å­¦ç”Ÿæ•°å­¦å»ºæ¨¡ç«èµ›**ï¼šå›½å®¶çº§äºŒç­‰å¥–ï¼ˆ2016 å¹´ï¼‰
- **FASHIONAI å…¨çƒæŒ‘æˆ˜èµ›**ï¼šå¤èµ›ç¬¬ 3rdã€7thï¼ˆ2018 å¹´ï¼‰

## å­¦æœ¯å¥–é¡¹
- **ACM å¹¿å·åœ°åŒºä¼˜ç§€åšå£«è®ºæ–‡å¥–**ï¼š2023 å¹´
- **"å¾®è½¯å­¦è€…"å¥–å­¦é‡‘ï¼ˆ11 åäºšæ´² - å¤ªå¹³æ´‹åœ°åŒºæ°å‡ºåšå£«ç”Ÿï¼‰**ï¼š2021 å¹´
- **ç™¾åº¦å¥–å­¦é‡‘ï¼ˆå…¨çƒ 40 å¼ºï¼‰**ï¼š2021 å¹´
- **åšå£«ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ï¼ˆ0.2%ï¼‰**ï¼š2020 å¹´
- **ä¼˜ç§€å­¦ç”Ÿä¸€ç­‰å¥–å­¦é‡‘**ï¼š2016 å¹´
- **ä¼˜ç§€å­¦ç”ŸäºŒç­‰å¥–å­¦é‡‘**ï¼š2017 å¹´ã€2018 å¹´ã€2019 å¹´ã€2020 å¹´
- **å•é¡¹å¥–å­¦é‡‘**ï¼š2015 å¹´ 

# ç ”ç©¶ç»éªŒ

### AI Agent åŸºåº§æ¨¡å‹
*   **ç ”ç©¶æ–¹å‘**ï¼š
    1.  Agentçš„ä»»åŠ¡è§„åˆ’å’Œå·¥å…·è°ƒç”¨èƒ½åŠ›
    2.  é•¿æœŸè®°å¿†èƒ½åŠ›
    3.  èƒ½è‡ªä¸»æ“çºµGUIç•Œé¢ï¼ˆæ‰‹æœº/ç”µè„‘ï¼‰çš„GUI Agent
*   **æˆæœ**ï¼š
    1.    æå‡ºé¦–ä¸ª LLM çš„é•¿æœŸè®°å¿†æ¡†æ¶ï¼Œæ„å»ºæƒ…æ„Ÿé™ªä¼´æœºå™¨äººï¼ˆå‘è¡¨äº AAAI-2024ï¼‰
    2.    ä¸šç•Œæœ€å¼ºå¼€æºGUI AgentåŸºåº§æ¨¡å‹UI-TARsåŠAgentåº”ç”¨Agent TARSï¼ŒGithubæ˜Ÿæ ‡è¾¾åˆ°6.2K
    3.    å¼€æºå·¥å…·å¢å¼ºçš„Agentå¼ºåŒ–å­¦ä¹ è®­ç»ƒæ¡†æ¶ReTool, æå‡æ¨¡å‹åœ¨å¥¥æ—åŒ¹å…‹æ•°å­¦ç«èµ›ä¸­çš„æ€§èƒ½+20%ã€‚
    4.    åŸºäºåä¸ºç›˜å¤æ„å»ºå¤æ‚ä»»åŠ¡è§„åˆ’ã€åæ€æ”¹è¿›å’Œå·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œç›¸å…³ç ”ç©¶æŠ•ç¨¿ ACL-2024

### å¼ºåŒ–å­¦ä¹ å¢å¼ºæ¨¡å‹æ¨ç†èƒ½åŠ›

### å¤§è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆæ•°æ®é£è½® ï¼ˆåä¸º &amp; å­—èŠ‚Seedï¼‰

*   **ç ”ç©¶ç›®æ ‡**ï¼šåˆ©ç”¨ç°ç½‘å›æµæ•°æ®åŠæ¨¡å‹è‡ªæ¢ç´¢æ•°æ®æå‡æ¨¡å‹èƒ½åŠ›ï¼Œæ„å»ºè‡ªåŠ¨åŒ–æ•°æ®é£è½®
*   **æˆæœ**ï¼šå¤šé¡¹è½åœ°æˆæœï¼Œé€šè¿‡åˆ©ç”¨ç”¨æˆ·æ•°æ®ï¼Œå¿«é€Ÿæå‡æ¨¡å‹æ€§èƒ½å¹¶ä¿®è¡¥ç°ç½‘é—®é¢˜

### å¤§è¯­è¨€æ¨¡å‹çš„è¶…çº§å¯¹é½ï¼ˆè‡ªæˆ‘å­¦ä¹ ï¼‰ç ”ç©¶ ï¼ˆåä¸º &amp; å­—èŠ‚Seedï¼‰
*   **ç ”ç©¶ç›®æ ‡**ï¼šæ¢ç´¢ LLM é«˜æ•ˆå¯¹é½ï¼Œå‡å°‘äººç±»å¹²é¢„æˆæœ¬

*   **æ ¸å¿ƒæ–¹æ³•**ï¼šè‡ªä¸»æ¢ç´¢ (Exploration)ã€è‡ªåŠ¨é«˜æ•ˆåé¦ˆ (Evaluation)ã€åŸºäºåé¦ˆçš„å¯¹é½å­¦ä¹  (Evolution)

*   **æˆæœ**ï¼š
    *   è®ºæ–‡æŠ•ç¨¿ ICMLï¼ŒACLåŠAAAI
    *   é¡¹ç›®è½åœ°ï¼Œæ¨¡å‹æ•ˆæœæå‡ 10% ä»¥ä¸Š
    *   è·è¯„åä¸ºä¸­å¤®ç ”ç©¶é™¢åˆ›æ–°å…ˆé”‹

### å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨åŒ–æŒ‡ä»¤æ„é€ åŠæŒ‡ä»¤å¾®è°ƒ

*   **ç ”ç©¶ç›®æ ‡**ï¼šæ„å»ºè‡ªåŠ¨æ•°æ®æ„é€ çš„æ–¹æ¡ˆï¼Œå‡è½»äººå·¥æ„é€ æŒ‡ä»¤å¯¹çš„æ ‡æ³¨æˆæœ¬ï¼Œå¢å¼ºæ¨¡å‹æŒ‡ä»¤ç†è§£å’Œæ³›åŒ–èƒ½åŠ›
*   **æˆæœ**ï¼šå¼€å‘è‡ªåŠ¨æŒ‡ä»¤æ¨¡æ¿ç”Ÿæˆæ¡†æ¶ï¼Œå¯è‡ªåŠ¨æ€»ç»“å½’çº³ä»»åŠ¡æ•°æ®ç”Ÿæˆä»»åŠ¡æè¿°å’Œæ¨¡æ¿ï¼Œè‡ªåŠ¨æ„é€  AIGC ä»»åŠ¡æ•°æ®ï¼Œæœ‰æ•ˆæå‡æ¨¡å‹æŒ‡ä»¤ç†è§£å’Œæ³›åŒ–èƒ½åŠ›

***

### åŸºäºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„æ ‡å‡†æµ‹è¯„

*   **ç ”ç©¶æˆæœ**ï¼š
    *   æ„å»ºé’ˆå¯¹ LLM åœ¨äººç±»æ ‡å‡†åŒ–è€ƒè¯•ä¸­è¡¨ç°çš„è¯„æµ‹ Benchmarkâ€”â€”AGIEval
    *   è¯„ä¼° GPT-4ã€ChatGPT å’Œ Text-Davinci-003 ç­‰é¡¶çº§åŸºç¡€æ¨¡å‹ï¼Œåˆ†ææ¨¡å‹èƒ½åŠ›ï¼Œæ­ç¤ºä¼˜ç¼ºç‚¹
    *   AGIEval è¯„æµ‹æ•°æ®é›†è¢«ç”¨äº InternLMã€baichuan-7B ç­‰ä¼—å¤šçŸ¥åå¤§æ¨¡å‹è¯„æµ‹

***

### é’ˆå¯¹é—®ç­”ç³»ç»Ÿå’Œé€šç”¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„é€šç”¨æ¨¡å‹ç ”ç©¶

*   **ç ”ç©¶æ–¹æ³•**ï¼šä½¿ç”¨çµæ´»å¯æ‰©å±•çš„ç»“æ„åŒ– prompt æŠ€æœ¯æ­å»ºé€šç”¨è‡ªç„¶è¯­è¨€é—®ç­”æ¨¡å‹åŠé€šç”¨è‡ªç„¶è¯­è¨€ä»»åŠ¡æ¨¡å‹
*   **ç ”ç©¶ä¼˜åŠ¿**ï¼šä¿ƒè¿›ä»»åŠ¡é—´çŸ¥è¯†å…±äº«ï¼ŒåŒºåˆ†ä¸åŒä»»åŠ¡å·®å¼‚æ€§

## åšå£«æœŸé—´ç ”ç©¶æ–¹å‘ï¼šåŸºäºçŸ¥è¯†çš„è‡ªç„¶è¯­è¨€æ¨¡å‹æ¨ç†
| ç ”ç©¶æ–¹å‘ | æ ¸å¿ƒæ–¹æ³• | åº”ç”¨ä»»åŠ¡ | æˆæœäº®ç‚¹ |
| --- | --- | --- | --- |
| åŸºäºéç»“æ„åŒ–çŸ¥è¯†çš„æœºå™¨æ¨ç† | ä»éç»“æ„åŒ–æ–‡æœ¬æŠ½å–åŠç»“æ„åŒ–çŸ¥è¯†è¯­ä¹‰å›¾ï¼ŒåŸºäºå›¾çš„æ¨ç†æ¨¡å‹åœ¨è¯­ä¹‰å›¾ä¸Šèšåˆä¿¡æ¯å¹¶é¢„æµ‹ | å‡æ–°é—»æ£€æµ‹ï¼ˆACL2021ï¼‰ã€äº‹å®æ£€æµ‹ï¼ˆACL2020ï¼‰ã€DeepFakeæ£€æµ‹ï¼ˆEMNLP2020ï¼‰ | å»ºç«‹åŸºäºå›¾çš„æ¨ç†æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³å¤šç±»è‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ |
| åŸºäºç»“æ„åŒ–çŸ¥è¯†çš„æœºå™¨æ¨ç† | åŸºäºçŸ¥è¯†åº“çš„é¢„è®­ç»ƒæ–¹æ³•å­¦ä¹ å®ä½“è¡¨ç¤ºï¼Œåˆ©ç”¨ç¥ç»æ¨¡å—åŒ–ç½‘ç»œå®ç°è¡¨æ ¼é€»è¾‘æ“ä½œ | åŸºäºè¡¨æ ¼çš„äº‹å®æ£€æµ‹ä»»åŠ¡ï¼ˆACL 2020ï¼‰ã€å¸¸è¯†é—®ç­”ä»»åŠ¡ï¼ˆNLPCC 2019ï¼‰ | æå‡ºåˆ›æ–°æ–¹æ³•ï¼Œä¸ºç»“æ„åŒ–çŸ¥è¯†æ¨ç†ä»»åŠ¡æä¾›æœ‰æ•ˆè§£å†³æ–¹æ¡ˆ |
| åŸºäºé€»è¾‘çŸ¥è¯†çš„å¤æ‚æ¨ç† | LReasoneræ–¹æ³•ç”¨é€»è¾‘è§„åˆ™æ‰©å±•çŸ¥è¯†ï¼›æå‡ºæ–°åŸºå‡†æ•°æ®é›†AR-LSATä¸åˆ†ææ¨ç†ç³»ç»ŸARMï¼›é‡‡ç”¨ç¥ç»-ç¬¦å·æ–¹æ³•ï¼›ä»¥é€»è¾‘çŸ¥è¯†ä¸ºç½‘ç»œå­¦ä¹ çº¦æŸ | ç¾å›½å¸æ³•å­¦é™¢å…¥å­¦è€ƒè¯•ã€ç»†ç²’åº¦å®£ä¼ æ–‡æœ¬æ£€æµ‹ä»»åŠ¡ï¼ˆEMNLP 2020ï¼‰ | LReasoneråœ¨ReCLoræµ‹è¯„æ¦œé¦–æ¬¡è¶…è¶Šäººç±»è¡¨ç°ï¼Œæå‡ºå¤šé¡¹åˆ›æ–°æ€§æ–¹æ³•å’Œæ•°æ®é›† |
| åŸºäºæ··åˆçŸ¥è¯†çš„æœºå™¨æ¨ç† | å¤šæ¨¡æ€çŸ¥è¯†æ£€ç´¢æ¨¡å‹ï¼ŒåŸºäºè¯æ®é“¾çš„å¤šè·³æ¨ç†æ¨¡å‹ï¼Œé“¾å¼æ¨ç†é¢„è®­ç»ƒä»»åŠ¡ | æ–‡æœ¬-è¡¨æ ¼å¼€æ”¾é¢†åŸŸå¤šè·³é—®ç­”ä»»åŠ¡ | æå‡æ£€ç´¢ä¸é—®ç­”ä»»åŠ¡æ€§èƒ½ï¼Œå¢å¼ºæ¨¡å‹é€šç”¨æ€§ |

</div>

<div class="content-section homepage-section">
# ğŸ“ Homepages
- Personal Pages: https://zhongwanjun.github.io (updated recentlyğŸ”¥)
- Google Scholar: https://scholar.google.com/citations?user=FGIZfyQAAAAJ

</div>

<div class="content-section news-section">
# ğŸ”¥ News
- *2025.04*: ğŸ‰ Joined ByteDance Seed Edge team as Senior Research Scientist focusing on Large Language Models and Agent foundation models!
- *2025.04* Released **ReTool**: A reinforcement learning-based multi-turn tool-use agent training framework!
- *2025.04*: ğŸ‰ **Seed-VL-v1.5** technical report released, advancing multi-modal models with great understanding and reasoning capabilities!
- *2025.04*: ğŸ‰ **Seed-Thinking-v1.5** technical report released, advancing superb reasoning models with reinforcement learning
- *2025.01*: ğŸ‰ Released **UI-TARS**: Industry's open-source GUI+Game Agent foundation model with 6.2K+ GitHub stars!
- *2024.06*: ğŸ‰ Joined ByteDance TopSeed program as a Senior Research Scientist!
- *2023.01*: ğŸ‰ **AGIEval** benchmark accepted at NAACL 2024 - A human-centric benchmark for evaluating foundation models with 500+ citations!
- *2023.06*: ğŸ‰ Joined Huawei Noah's Ark Lab as Research Scientist and became a member of Huawei TopMind program
- *2023.06*: ğŸ‰ Successfully defended Ph.D. thesis at Sun Yat-sen University (SYSU)
- *2021.11*: ğŸ† Won **Microsoft Research Fellowship Award** (11 outstanding Ph.D. students in Asia-Pacific area each year)
- *2021.09*: ğŸ† Won **Baidu Scholarship** (Top 40 globally)
- *2020.11*: ğŸ† Won **National Scholarship for Doctoral Students** (Top 0.2%)
</div>

<div class="content-section publications-section">

# ğŸ“ Publications 
## Works in Seed
- ``Seed Technical Report`` [Seed1.5-VL Technical Report](https://arxiv.org/pdf/2505.07062)
- ``Seed Technical Report`` [Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning](https://arxiv.org/pdf/2504.13914v1)
- ``Seed Technical Report`` [UI-TARS: Pioneering Automated GUI Interaction with Native Agents](https://arxiv.org/abs/2501.12326)
-  ``Sub. to NeurIPS 2025`` [Retool: Reinforcement learning for strategic tool use in llms](https://arxiv.org/pdf/2504.11536?), Jiazhan Feng, Shijue Huang, Xingwei Qu, Ge Zhang, Yujia Qin, Baoquan Zhong, Chengquan Jiang, Jinxin Chi, **Wanjun Zhong**
- ``Arxiv`` [Autokaggle: A multi-agent framework for autonomous data science competitions](https://arxiv.org/pdf/2410.20424?), Ziming Li, Qianbo Zang, David Ma, Jiawei Guo, Tuney Zheng, Minghao Liu, Xinyao Niu, Yue Wang, Jian Yang, Jiaheng Liu, **Wanjun Zhong**, Wangchunshu Zhou, Wenhao Huang, Ge Zhang
- ``EMNLP 2025`` [Otc: Optimal tool calls via reinforcement learning](https://arxiv.org/pdf/2504.14870?), Hongru Wang, Cheng Qian, **Wanjun Zhong**, Xiusi Chen, Jiahao Qiu, Shijue Huang, Bowen Jin, Mengdi Wang, Kam-Fai Wong, Heng Ji

<!-- <div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2019</div><img src='images/fs.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[FastSpeech: Fast, Robust and Controllable Text to Speech](https://papers.nips.cc/paper/8580-fastspeech-fast-robust-and-controllable-text-to-speech.pdf) \\
**Yi Ren**, Yangjun Ruan, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu

[**Project**](https://speechresearch.github.io/fastspeech/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- FastSpeech is the first fully parallel end-to-end speech synthesis model.
- **Academic Impact**: This work is included by many famous speech synthesis open-source projects, such as [ESPNet ![](https://img.shields.io/github/stars/espnet/espnet?style=social)](https://github.com/espnet/espnet). Our work are promoted by more than 20 media and forums, such as [æœºå™¨ä¹‹å¿ƒ](https://mp.weixin.qq.com/s/UkFadiUBy-Ymn-zhJ95JcQ)ã€[InfoQ](https://www.infoq.cn/article/tvy7hnin8bjvlm6g0myu).
- **Industry Impact**: FastSpeech has been deployed in [Microsoft Azure TTS service](https://techcommunity.microsoft.com/t5/azure-ai/neural-text-to-speech-extends-support-to-15-more-languages-with/ba-p/1505911) and supports 49 more languages with state-of-the-art AI quality. It was also shown as a text-to-speech system acceleration example in [NVIDIA GTC2020](https://resources.nvidia.com/events/GTC2020s21420).
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2021</div><img src='images/fs2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[FastSpeech 2: Fast and High-Quality End-to-End Text to Speech](https://arxiv.org/abs/2006.04558) \\
**Yi Ren**, Chenxu Hu, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, Tie-Yan Liu

[**Project**](https://speechresearch.github.io/fastspeech2/) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:LkGwnXOMwfcC'></span></strong>
  - This work is included by many famous speech synthesis open-source projects, such as [PaddlePaddle/Parakeet ![](https://img.shields.io/github/stars/PaddlePaddle/PaddleSpeech?style=social)](https://github.com/PaddlePaddle/PaddleSpeech), [ESPNet ![](https://img.shields.io/github/stars/espnet/espnet?style=social)](https://github.com/espnet/espnet) and [fairseq ![](https://img.shields.io/github/stars/pytorch/fairseq?style=social)](https://github.com/pytorch/fairseq).
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR 2024</div><img src='images/mega.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis](https://openreview.net/forum?id=mvMI3N4AvD) \\ 
Ziyue Jiang, Jinglin Liu, **Yi Ren**, et al.

[**Project**](https://boostprompt.github.io/boostprompt/) 
  - This work has been deployed on many TikTok products.
  - Advandced zero-shot voice cloning model.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2022</div><img src='images/diffsinger.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism](https://arxiv.org/abs/2105.02446) \\
Jinglin Liu, Chengxi Li, **Yi Ren**, Feiyang Chen, Zhou Zhao

- Many [video demos](https://www.bilibili.com/video/BV1be411N7JA) created by the [DiffSinger community](https://github.com/openvpi) are released.
- DiffSinger was introduced in [a very popular video](https://www.bilibili.com/video/BV1uM411t7ZJ) (1600k+ views) on Bilibili!

- [**Project**](https://diffsinger.github.io/) \| [![](https://img.shields.io/github/stars/NATSpeech/NATSpeech?style=social&label=DiffSpeech Stars)](https://github.com/NATSpeech/NATSpeech) \| [![](https://img.shields.io/github/stars/MoonInTheRiver/DiffSinger?style=social&label=DiffSinger Stars)](https://github.com/MoonInTheRiver/DiffSinger) \| [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=Demo)](https://huggingface.co/spaces/NATSpeech/DiffSpeech)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2021</div><img src='images/portaspeech.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[PortaSpeech: Portable and High-Quality Generative Text-to-Speech](https://arxiv.org/abs/2109.15166) \\
**Yi Ren**, Jinglin Liu, Zhou Zhao

[**Project**](https://portaspeech.github.io/) \| [![](https://img.shields.io/github/stars/NATSpeech/NATSpeech?style=social&label=Code+Stars)](https://github.com/NATSpeech/NATSpeech) \| [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=Demo)](https://huggingface.co/spaces/NATSpeech/PortaSpeech)
</div>
</div> -->

## Large Language Model Reasoning
- ``Seed Technical Report`` [Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning](https://arxiv.org/pdf/2504.13914v1)
- ``ICLR 2025`` [G-llava: Solving geometric problem with multi-modal large language model](https://arxiv.org/abs/2312.11370), Jiahui Gao, Renjie Pi, Jipeng Zhang, Jiacheng Ye, **Wanjun Zhong**, Yufei Wang, Lanqing Hong, Jianhua Han, Hang Xu, Zhenguo Li, Lingpeng Kong 
- ``ACL 2025`` [Self-reasoning language models: Unfold hidden reasoning chains with few reasoning catalyst](https://arxiv.org/pdf/2505.14116), Hongru Wang, Deng Cai, **Wanjun Zhong**, Shijue Huang, Jeff Z Pan, Zeming Liu, Kam-Fai Wong
- ``Information Processing &amp; Management`` [Adaptive-solver framework for dynamic strategy selection in large language model reasoning](https://arxiv.org/pdf/2310.01446), Jianpeng Zhou, **Wanjun Zhong**, Yanlin Wang, Jiahai Wang
- ``AAAI 2025`` [Exploring iterative enhancement for improving learnersourced multiple-choice question explanations with large language models](https://ojs.aaai.org/index.php/AAAI/article/download/35164/37319), Qiming Bao, Juho Leinonen, Alex Yuxuan Peng, **Wanjun Zhong**, GaÃ«l Gendron, Timothy Pistotti, Alice Huang, Paul Denny, Michael Witbrock, Jiamou Liu




## General Agent Model &amp; System
### Multi-modal Agent (GUI etc.)
- ``Seed Technical Report`` [UI-TARS: Pioneering Automated GUI Interaction with Native Agents](https://arxiv.org/abs/2501.12326), Yujia Qin, Yining Ye, Junjie Fang, Haoming Wang, Shihao Liang, Shizuo Tian, Junda Zhang, Jiahao Li, Yunxin Li, Shijue Huang, **Wanjun Zhong**, Kuanye Li, Jiale Yang, Yu Miao, Woyu Lin, Longxiang Liu, Xu Jiang, Qianli Ma, Jingyu Li, Xiaojun Xiao, Kai Cai, Chuang Li, Yaowei Zheng, Chaolin Jin, Chen Li, Xiao Zhou, Minchao Wang, Haoli Chen, Zhaojian Li, Haihua Yang, Haifeng Liu, Feng Lin, Tao Peng, Xin Liu, Guang Shi

### Tool-Learning Agent
- ``Sub. to NeurIPS 2025`` [Retool: Reinforcement learning for strategic tool use in llms](https://arxiv.org/pdf/2504.11536?), Jiazhan Feng, Shijue Huang, Xingwei Qu, Ge Zhang, Yujia Qin, Baoquan Zhong, Chengquan Jiang, Jinxin Chi, **Wanjun Zhong**
- ``Arxiv`` [Autokaggle: A multi-agent framework for autonomous data science competitions](https://arxiv.org/pdf/2410.20424?), Ziming Li, Qianbo Zang, David Ma, Jiawei Guo, Tuney Zheng, Minghao Liu, Xinyao Niu, Yue Wang, Jian Yang, Jiaheng Liu, **Wanjun Zhong**, Wangchunshu Zhou, Wenhao Huang, Ge Zhang
- ``EMNLP 2025`` [Otc: Optimal tool calls via reinforcement learning](https://arxiv.org/pdf/2504.14870?), Hongru Wang, Cheng Qian, **Wanjun Zhong**, Xiusi Chen, Jiahao Qiu, Shijue Huang, Bowen Jin, Mengdi Wang, Kam-Fai Wong, Heng Ji
- ``ACL 2024`` [Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios](https://arxiv.org/pdf/2401.15670), Shijue Huang, **Wanjun Zhong**, Jianqiao Lu, Qi Zhu, Jiahui Gao, Weiwen Liu, Yutai Hou, Xingshan Zeng, Yasheng Wang, Lifeng Shang, Xin Jiang, Ruifeng Xu, Qun Liu 
  
### Code Agent
- ``Arxiv`` [Agents in software engineering: Survey, landscape, and vision](https://arxiv.org/pdf/2409.09030?), Yanlin Wang, **Wanjun Zhong**, Yanxian Huang, Ensheng Shi, Min Yang, Jiachi Chen, Hui Li, Yuchi Ma, Qianxiang Wang, Zibin Zheng 
- ``ICSME 2023`` [You Augment Me: Exploring ChatGPT-based Data Augmentation for Semantic Code Search](https://arxiv.org/pdf/2208.03229.pdf), Yanlin Wang, Lianghong Guo, Ensheng Shi, Wenqing Chen, Jiachi Chen, **Wanjun Zhong**, Menghan Wang, Hui Li, Hongyu Zhang, Ziyu Lyu, Zibin Zheng  
-  ``ISSTA 24 - Outstanding Paper Award`` [When to stop? towards efficient code generation in llms with excess token prevention](https://arxiv.org/pdf/2407.20042), Lianghong Guo, Yanlin Wang, Ensheng Shi, **Wanjun Zhong**, Hongyu Zhang, Jiachi Chen, Ruikai Zhang, Yuchi Ma, Zibin Zheng

### Agent Memory
- ``AAAI 2024`` [MemoryBank: Enhancing Large Language Models with Long-Term Memory](https://arxiv.org/abs/2305.10250), **Wanjun Zhong**, Lianghong Guo, Qiqi Gao, He Ye, Yanlin Wang  

### Agent-driven Training
- ``arXiv 2024`` [YODA: Teacher-Student Progressive Learning for Language Models](https://arxiv.org/pdf/2401.15670), Jianqiao Lu*, **Wanjun Zhong***, Yufei Wang, Zhijiang Guo, Qi Zhu, Wenyong Huang, Yanlin Wang, Fei Mi, Baojun Wang, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu (* equal contribution) 

## Benchmark and Evaluation
- ``NAACL 2024`` [AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models](https://arxiv.org/abs/2304.06364), **Wanjun Zhong**, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen, Nan Duan 
-  ``EMNLP 2024`` [CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models](https://arxiv.org/abs/2403.03514), Zexuan Qiu, Jingjing Li, Shijue Huang, **Wanjun Zhong**, Irwin King  
- ``ACL 2024 Workshop`` [PerLTQA: A Personal Long-Term Memory Dataset for Memory Classification, Retrieval, and Synthesis in Question Answering](https://arxiv.org/abs/2402.16288), Yiming Du, Hongru Wang, Zhengyi Zhao, Bin Liang, Baojun Wang, **Wanjun Zhong**, Zezhong Wang, Kam-Fai Wong 
- ``ACL 2024`` [Followbench: A multi-level fine-grained constraints following benchmark for large language models](https://arxiv.org/abs/2310.20410), Yuxin Jiang, Yufei Wang, Xingshan Zeng, **Wanjun Zhong**, Liangyou Li, Fei Mi, Lifeng Shang, Xin Jiang, Qun Liu, Wei Wang 


## Self-Learning of LLMs
- ``AAAI 2025`` [Empowering Self-Learning of LLMs: Inner Knowledge Explicitation as a Catalyst](https://ojs.aaai.org/index.php/AAAI/article/view/34590/36745), Shijue Huang, **Wanjun Zhong**, Deng Cai, Fanqi Wan, Chengyi Wang, Mingxuan Wang, Mu Qiao, Ruifeng Xu
- ``arXiv 2023`` [SELF: Language-driven self-evolution for large language model](https://arxiv.org/abs/2403.03514), Jianqiao Lu, **Wanjun Zhong**, Wenyong Huang, Yufei Wang, Fei Mi, Baojun Wang, Weichao Wang, Lifeng Shang, Qun Liu  

## General LLM Training   
- ``arXiv 2023`` [Data management for large language models: A survey](https://arxiv.org/abs/2312.01700), Zige Wang, **Wanjun Zhong**, Yufei Wang, Qi Zhu, Fei Mi, Baojun Wang, Lifeng Shang, Xin Jiang, Qun Liu  
- ``arXiv 2023`` [Aligning large language models with human: A survey](https://arxiv.org/abs/2307.12966), Yufei Wang, **Wanjun Zhong**, Liangyou Li, Fei Mi, Xingshan Zeng, Wenyong Huang, Lifeng Shang, Xin Jiang, Qun Liu  
- ``ACL 2024`` [Learning to Edit: Aligning LLMs with Knowledge Editing](https://arxiv.org/pdf/2402.11905), Yuxin Jiang, Yufei Wang, Chuhan Wu, **Wanjun Zhong**, Xingshan Zeng, Jiahui Gao, Liangyou Li, Xin Jiang, Lifeng Shang, Ruiming Tang, Qun Liu, Wei Wang   
- ``ICSME 2023`` [You Augment Me: Exploring ChatGPT-based Data Augmentation for Semantic Code Search](https://arxiv.org/pdf/2208.03229.pdf), Yanlin Wang, Lianghong Guo, Ensheng Shi, Wenqing Chen, Jiachi Chen, **Wanjun Zhong**, Menghan Wang, Hui Li, Hongyu Zhang, Ziyu Lyu, Zibin Zheng  
 

 
- ``ACL 2023`` [CONE: An Efficient COarse-to-fiNE Alignment Framework for Long Video Temporal Grounding](https://arxiv.org/pdf/2209.10918.pdf), Zhijian Hou*, **Wanjun Zhong***, Leiji, Kun Yan, Difei Gao, Wing-Kwong Chan, Chong-Wah Ngo, Zheng Shou, Nan Duan (* equal contribution)  

## Previous Work Before 2023
### Multi-Modal
- ``ICME 2023`` [Semantic Composition and Alignment with Cross-Modality-Aware Syntactic Hypergraph Convolutional Network for Video Question Answering](https://arxiv.org/pdf/2009.10297.pdf), Zenan Xu*, **Wanjun Zhong***, Qinliang Su, Zijing Ou, Fuwei Zhang (* equal contribution)  
- ``ECCV Challenge 2022`` [An Efficient COarse-to-fiNE Alignment Framework @ Ego4D Natural Language Queries Challenge 2022](https://arxiv.org/abs/2210.05197.pdf), Zhijian Hou*, **Wanjun Zhong***, Leiji, Kun Yan, Difei Gao, Wing-Kwong Chan, Chong-Wah Ngo, Zheng Shou, Nan Duan (* equal contribution) [[code]](https://github.com/Jun-jie-Huang/OTTeR)  

### Knowledge-enhanced Language Model Reasoning
- ``ACL 2022`` [Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers](https://arxiv.org/pdf/2210.11265.pdf), **Wanjun Zhong***, Tingting Ma*, Jiahai Wang, Jian Yin, Tiejun Zhao, Chin-Yew Lin, Nan Duan (* equal contribution)  
- ``EMNLP 2022`` [Mixed-modality Representation Learning and Pre-training for Joint Table-and-Text Retrieval in OpenQA](https://arxiv.org/abs/2210.05197.pdf), JunJie Huang, **Wanjun Zhong***, Qian Liu, Ming Gong, Daxin Jiang, Nan Duan (* equal contribution) [[code]](https://github.com/Jun-jie-Huang/OTTeR)  
- ``NeurIPS 2022`` [LogiGAN: Learning Logical Reasoning via Adversarial Pre-training](https://arxiv.org/pdf/2205.08794.pdf), Xinyu Pi*, **Wanjun Zhong***, Yan Gao, Jian-guang Lou, Nan Duan (* equal contribution) [[code]](https://github.com/microsoft/ContextualSP/tree/master/logigan)  
- ``IJCAI 2022 (Oral)`` [Reasoning over Hybrid Chain for Table-and-Text Open Domain Question Answering](https://arxiv.org/pdf/2201.05880.pdf), **Wanjun Zhong***, Junjie Huang*, Qian Liu, Ming Zhou, Jiahai Wang, Jian Yin, Nan Duan (* equal contribution) [[code]](https://github.com/zhongwanjun/CARP)  
- ``NAACL 2022`` [ProQA: Structural Prompt-based Pre-training for Unified Question Answering](https://openreview.net/pdf?id=g68eYTS0rzJ), **Wanjun Zhong***, Yifan Gao, Ning Ding, Yujia Qin, Zhiyuan Liu, Ming Zhou, Jiahai Wang, Jian Yin, Nan Duan (* equal contribution) [[code]](https://github.com/zhongwanjun/ProQA)  
- ``TASLP 2022`` [From LSAT: The Progress and Challenges of Complex Reasoning](https://arxiv.org/abs/2108.00648), Siyuan Wang, Zhongkun Liu, **Wanjun Zhong**, Ming Zhou, Zhongyu Wei, Zhumin Chen, Nan Duan  
- ``NAACL 2022`` [Analytical Reasoning of Text](https://arxiv.org/pdf/2104.06598.pdf), **Wanjun Zhong**, Siyuan Wang, Duyu Tang, Zenan Xu, Daya Guo, Jiahai Wang, Jian Yin, Ming Zhou, Nan Duan [[code]](https://github.com/zhongwanjun/AR-LSAT)  
- ``ACL 2022`` [Logic-Driven Context Extension and Data Augmentation for Logical Reasoning of Text](https://arxiv.org/pdf/2004.03070.pdf), Siyuan Wang, **Wanjun Zhong**, Duyu Tang, Zhongyu Wei, Zhihao Fan, Daxin Jiang, Ming Zhou, Nan Duan [[code]](https://github.com/WangsyGit/LReasoner)  
Here is the formatted list in the requested style:
- ``EMNLP 2021`` [WhiteningBERT: An Easy Unsupervised Sentence Embedding Approach](https://arxiv.org/abs/2104.01767), Junjie Huang, Duyu Tang, **Wanjun Zhong**, Shuai Lu, Linjun Shou, Ming Gong, Daxin Jiang, Nan Duan  
- ``ACL 2021`` [UserAdapter: Few-Shot User Learning in Sentiment Analysis](https://aclanthology.org/2021.findings-acl.129.pdf), **Wanjun Zhong**, Duyu Tang, Jiahai Wang, Jian Yin, Nan Duan  
- ``ACL 2021`` [Syntax-Enhanced Pre-trained Model](https://arxiv.org/pdf/2012.14116.pdf), Zenan Xu, Daya Guo, Duyu Tang, Qinliang Su, Linjun Shou, Ming Gong, **Wanjun Zhong**, Xiaojun Quan, Daxin Jiang, Nan Duan  
- ``ACL 2021`` [Compare to The Knowledge: Graph Neural Fake News Detection with External Knowledge](), Linmei Hu, Tianchi Yang, Luhao Zhang, **Wanjun Zhong**, Duyu Tang, Chuan Shi, Nan Duan, Ming Zhou  
- ``EMNLP 2020 (Oral)`` [Neural Deepfake Detection with Factual Structure of Text](https://arxiv.org/pdf/2010.07475.pdf), **Wanjun Zhong**, Duyu Tang, Zenan Xu, Ruize Wang, Nan Duan, Ming Zhou, Jiahai Wang, Jian Yin [[video]](https://slideslive.com/38938858/neural-deepfake-detection-with-factual-structure-of-text)  
- ``EMNLP 2020`` [Leveraging declarative knowledge in text and first-order logic for fine-grained propaganda detection](https://arxiv.org/pdf/2004.14201.pdf), Ruize Wang, Duyu Tang, Nan Duan, **Wanjun Zhong**, Zhongyu Wei, Xuanjing Huang, Daxin Jiang, Ming Zhou  
- ``ACL 2020`` [LogicalFactChecker: Leveraging Logical Operations for Fact Checking with Graph Module Network](https://www.aclweb.org/anthology/2020.acl-main.539.pdf), **Wanjun Zhong**, Duyu Tang, Zhangyin Feng, Nan Duan, Ming Zhou, Ming Gong, Linjun Shou, Daxin Jiang, Jiahai Wang, Jian Yin [[video]](https://slideslive.com/38928864/logicalfactchecker-leveraging-logical-operations-for-fact-checking-with-graph-module-network)  
- ``ACL 2020`` [Reasoning Over Semantic-Level Graph for Fact Checking](https://www.aclweb.org/anthology/2020.acl-main.549.pdf), **Wanjun Zhong**, Jingjing Xu, Duyu Tang, Zenan Xu, Nan Duan, Ming Zhou, Jiahai Wang, Jian Yin [[video]](https://slideslive.com/38928866/reasoning-over-semanticlevel-graph-for-fact-checking)  
- ``NLPCC 2019`` [Improving Question Answering by Commonsense-Based Pre-Training](https://arxiv.org/pdf/1809.03568.pdf), **Wanjun Zhong**, Duyu Tang, Nan Duan, Ming Zhou, Jiahai Wang, Jian Yin  
- ``AI Open 2023`` [Improving Task Generalization via Unified Schema Prompt](https://arxiv.org/pdf/2208.03229.pdf), **Wanjun Zhong**, Yifan Gao, Ning Ding, Zhiyuan Liu, Ming Zhou, Jiahai Wang, Jian Yin, Nan Duan 
- ``arXiv 2020`` [A Heterogeneous Graph with Factual, Temporal and Logical Knowledge for Question Answering Over Dynamic Contexts](https://arxiv.org/pdf/2009.10297.pdf), **Wanjun Zhong**, Duyu Tang, Nan Duan, Ming Zhou, Jiahai Wang, Jian Yin  
 

</div>

<div class="content-section honors-section">
# ğŸ– Honors and Awards
- *2024* å­—èŠ‚è·³åŠ¨TopSeedäººæ‰è®¡åˆ’ (ByteDance TopSeed)
- *2023* ACMä¸­å›½-å¹¿å·åˆ†ä¼šä¼˜ç§€åšå£«è®ºæ–‡å¥– (ACM Outstanding Doctoral Thesis Award on China-Guangzhou)
- *2023* åä¸ºå¤©æ‰å°‘å¹´äººæ‰ (Huawei TopMinds)
- *2021* [Microsoft Research Fellowship Award](https://www.microsoft.com/en-us/research/academic-program/phd-fellowship/#!people) (11 outstanding Ph.D. students in computer science in the Asia-Pacific region each year)  
- *2021* Baidu Scholarship (Global Top 40)
- *2021* National Scholarship of Ph.D., 2020 (Top 0.2%)
- *2016* The First Prize Scholarship


# ğŸ† Competition Award
- *2023* Champion of CVPR 2023 Ego4D Challenge for Episodic Memory Natural Language Queries
- *2022* 3rd of ECCV 2022 Ego4D Challenge for Episodic Memory Natural Language Queries
- *2018* Merit Awards of Global Artificial Intelligence Application Competition
- *2018* Rank 3rd, 7th in the quarter-finals of the 2018 FASHIONAI GLOBAL CHALLENGE

</div>

<div class="content-section others-section">

# ğŸ“– Educations
- *2018.09 - 2023.06*, Ph.D. in Computer Science and Technology, Sun Yat-sen University (SYSU), Joint Ph.D. program with Microsoft Research Asia (MSRA)
- *2014.09 - 2018.06*, Bachelor in Software Engineering, School of Data Science and Computer Science, Sun Yat-sen University (SYSU)

# ğŸ’¼ Work Experience
- *2024.06 - Present*, **Senior Research Scientist**, ByteDance Seed Edge Team, Beijing
  - Member of TopSeed program
  - Focus: Large Language Models, Reasoning towards AGI, Agent foundation models
- *2023.06 - 2024.06*, **Research Scientist (TopMind Program Member)**, Huawei Noah's Ark Lab, Speech &amp; Semantic Lab, Shenzhen
  - Focus: Large Language Model instruction tuning, data flywheel, Agent super-alignment and complex reasoning

# ğŸ’¬ Academic Supervision
- **Ph.D. Advisors**: Dr. Ming Zhou (Microsoft Research Asia), Prof. Jian Yin (SYSU), Prof. Jiahai Wang (SYSU)
- **Mentor at MSRA**: Dr. Nan Duan (Natural Language Computing Group)

# ğŸ† Competition Awards
- **CVPR Ego4D Challenge for Episodic Memory Natural Language Queries**: 1st Place (2023)
- **ECCV Ego4D Challenge for Episodic Memory Natural Language Queries**: 3rd Place (2022)
- **Global (Nanjing) AI Application Competition**: Outstanding Award (2018)
- **National Mathematical Contest in Modeling**: National Second Prize (2016)
- **FASHIONAI Global Challenge**: 3rd &amp; 7th in Semi-finals (2018)

# ğŸ”¬ Research Internship
- *2018.06 - 2023.06*, **Research Intern**, Natural Language Computing Group, Microsoft Research Asia (MSRA), Beijing
  - Long-term internship as part of joint Ph.D. program
  - Mentor: Dr. Nan Duan

</div>

          </section>
        </div>
      </article>
    </div>

    <script src="/assets/js/main.min.js"></script>



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', "");
</script>


<script>
    $(document).ready(function () {
        
        var gsDataBaseUrl = 'https://cdn.jsdelivr.net/gh/zhongwanjun/wanjun.github.io@'
        
        $.getJSON(gsDataBaseUrl + "google-scholar-stats/gs_data.json", function (data) {
            // var totalCitation = data['citedby']
            // document.getElementById('total_cit').innerHTML = totalCitation;
            var citationEles = document.getElementsByClassName('show_paper_citations')
            Array.prototype.forEach.call(citationEles, element => {
                var paperId = element.getAttribute('data')
                var numCitations = data['publications'][paperId]['num_citations']
                element.innerHTML = '| Citations: ' + numCitations;
            });
        });
    })
</script>


  </body>
</html>
