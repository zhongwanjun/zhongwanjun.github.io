# 自我介绍

**钟宛君** || zhongwj25@mail2.sysu.edu.cn || https://zhongwanjun.github.io || (+86) 13609749192

我目前在字节跳动Seed团队担任研究员，参与TopSeed人才计划。
我的研究方向专注于大语言模型（LLMs）的复杂推理能力和Agent基座模型。
我们正在招聘**研究实习生**并寻求**学术合作**，欢迎随时联系我：[wanjun@bytedance.com](mailto:wanjun@bytedance.com)

在此之前，我曾在[华为诺亚方舟实验室](http://dev3.noahlab.com.hk/)担任高级研究员，参与华为天才少年计划。
我曾于2018至2023年期间，参与中山大学与微软亚洲研究院（MSRA）[联合培养博士项目](https://www.msra.cn/zh-cn/connections/academic-programs/joint-phd)，并在[中山大学](http://www.sysu.edu.cn/en/index.htm)[计算机科学与工程学院](http://sdcs.sysu.edu.cn/)获得博士学位。

作为联合培养博士生，我的导师包括[周明博士](https://scholar.google.co.jp/citations?user=a0w5c0gAAAAJ&hl=en)、[印鉴教授](http://sdcs.sysu.edu.cn/content/2505)和[王甲海教授](http://sdcs.sysu.edu.cn/content/2551)。我曾在MSRA自然语言计算组实习，导师为[段楠博士](https://nanduan.github.io/)。

我于2021年获得[微软学者奖学金](https://www.microsoft.com/en-us/research/academic-program/phd-fellowship/#!people)（每年亚太地区11名杰出博士生），并于2023年入选[华为天才少年计划](https://career.huawei.com/reccampportal/portal5/topminds.html)及ACM广州优秀博士论文奖。

我曾在顶级AI会议和期刊上发表了40多篇论文，包括NeurIPS、ICLR、ACL、EMNLP、TASLP、NAACL、AAAI、IJCAI、ISSTA等。

## 我的研究兴趣
- **大语言模型**
- **面向AGI的推理**
- **Agent基座模型**

# 工作及教育经历
- **字节跳动Seed Edge团队 - 大模型高级研究员**
    - **时间**：June 2024 – Now
    - **职责**：大语言模型和Agent方向高级研究员，
    - **项目经历**：
      - 豆包线上用户数据飞轮
      - Seed-Thinking长思维链推理模型：
      - Seed-Agent基座模型：
        - UI-TARS （业界开源的GUI+Game Agent基座模型）的训练
        - ReTool (Agent多轮工具调用强化学习训练框架)
        - MCP工具增强的DeepReseach模型及通用Agent基座模型训练
- **华为诺亚方舟实验室 - 语音语义实验室 - 研究员（天才少年）**
    - **时间**：June 2023 – June 2024
    - **项目经历**：大语言模型方向研究员，专门负责盘古基础语言模型指令微调、数据飞轮、Agent超级对齐和复杂推理等研究和落地。
- **微软亚洲研究院 - 联合培养项目长期实习**
    - **时间**：June 2018 – June 2023 

### 教育背景
- **中山大学 Sun Yat-Sen University (SYSU) - 微软亚洲研究院（MSRA）联合培养博士生项目**
    - **时间**：Sep 2018 – June 2023
    - **学位及专业**：计算机科学与技术专业直接攻读博士学位研究生
    - **指导导师**：周明博士（澜舟科技CEO，前MSRA副院长），印鉴教授（中山大学），王甲海教授（中山大学）
- **中山大学 Sun Yat-Sen University (SYSU)**
    - **时间**：Sep 2014 – June 2018
    - **学院及专业**：数据科学与计算机学院，软件工程专业学士 
  
# 荣誉&奖项
## 学术竞赛
- **CVPR - Ego4D Challenge for Episodic Memory Natural Language Queries**：冠军（2023 年）
- **ECCV - Ego4D Challenge for Episodic Memory Natural Language Queries**：季军（2022 年）
- **全球（南京）人工智能应用大赛**：优胜奖（2018 年）
- **国家大学生数学建模竞赛**：国家级二等奖（2016 年）
- **FASHIONAI 全球挑战赛**：复赛第 3rd、7th（2018 年）

## 学术奖项
- **ACM 广州地区优秀博士论文奖**：2023 年
- **"微软学者"奖学金（11 名亚洲 - 太平洋地区杰出博士生）**：2021 年
- **百度奖学金（全球 40 强）**：2021 年
- **博士研究生国家奖学金（0.2%）**：2020 年
- **优秀学生一等奖学金**：2016 年
- **优秀学生二等奖学金**：2017 年、2018 年、2019 年、2020 年
- **单项奖学金**：2015 年 

# 研究经验

### AI Agent 基座模型
*   **研究方向**：
    1.  Agent的任务规划和工具调用能力
    2.  长期记忆能力
    3.  能自主操纵GUI界面（手机/电脑）的GUI Agent
*   **成果**：
    1.    提出首个 LLM 的长期记忆框架，构建情感陪伴机器人（发表于 AAAI-2024）
    2.    业界最强开源GUI Agent基座模型UI-TARs及Agent应用Agent TARS，Github星标达到6.2K
    3.    开源工具增强的Agent强化学习训练框架ReTool, 提升模型在奥林匹克数学竞赛中的性能+20%。
    4.    基于华为盘古构建复杂任务规划、反思改进和工具调用能力，相关研究投稿 ACL-2024

### 强化学习增强模型推理能力

### 大语言模型的高效数据飞轮 （华为 & 字节Seed）

*   **研究目标**：利用现网回流数据及模型自探索数据提升模型能力，构建自动化数据飞轮
*   **成果**：多项落地成果，通过利用用户数据，快速提升模型性能并修补现网问题

### 大语言模型的超级对齐（自我学习）研究 （华为 & 字节Seed）
*   **研究目标**：探索 LLM 高效对齐，减少人类干预成本

*   **核心方法**：自主探索 (Exploration)、自动高效反馈 (Evaluation)、基于反馈的对齐学习 (Evolution)

*   **成果**：
    *   论文投稿 ICML，ACL及AAAI
    *   项目落地，模型效果提升 10% 以上
    *   获评华为中央研究院创新先锋

### 大规模语言模型的自动化指令构造及指令微调

*   **研究目标**：构建自动数据构造的方案，减轻人工构造指令对的标注成本，增强模型指令理解和泛化能力
*   **成果**：开发自动指令模板生成框架，可自动总结归纳任务数据生成任务描述和模板，自动构造 AIGC 任务数据，有效提升模型指令理解和泛化能力

***

### 基于大规模语言模型的标准测评

*   **研究成果**：
    *   构建针对 LLM 在人类标准化考试中表现的评测 Benchmark——AGIEval
    *   评估 GPT-4、ChatGPT 和 Text-Davinci-003 等顶级基础模型，分析模型能力，揭示优缺点
    *   AGIEval 评测数据集被用于 InternLM、baichuan-7B 等众多知名大模型评测

***

### 针对问答系统和通用自然语言处理任务的通用模型研究

*   **研究方法**：使用灵活可扩展的结构化 prompt 技术搭建通用自然语言问答模型及通用自然语言任务模型
*   **研究优势**：促进任务间知识共享，区分不同任务差异性

## 博士期间研究方向：基于知识的自然语言模型推理
| 研究方向 | 核心方法 | 应用任务 | 成果亮点 |
| --- | --- | --- | --- |
| 基于非结构化知识的机器推理 | 从非结构化文本抽取半结构化知识语义图，基于图的推理模型在语义图上聚合信息并预测 | 假新闻检测（ACL2021）、事实检测（ACL2020）、DeepFake检测（EMNLP2020） | 建立基于图的推理框架，有效解决多类自然语言理解任务 |
| 基于结构化知识的机器推理 | 基于知识库的预训练方法学习实体表示，利用神经模块化网络实现表格逻辑操作 | 基于表格的事实检测任务（ACL 2020）、常识问答任务（NLPCC 2019） | 提出创新方法，为结构化知识推理任务提供有效解决方案 |
| 基于逻辑知识的复杂推理 | LReasoner方法用逻辑规则扩展知识；提出新基准数据集AR-LSAT与分析推理系统ARM；采用神经-符号方法；以逻辑知识为网络学习约束 | 美国司法学院入学考试、细粒度宣传文本检测任务（EMNLP 2020） | LReasoner在ReCLor测评榜首次超越人类表现，提出多项创新性方法和数据集 |
| 基于混合知识的机器推理 | 多模态知识检索模型，基于证据链的多跳推理模型，链式推理预训练任务 | 文本-表格开放领域多跳问答任务 | 提升检索与问答任务性能，增强模型通用性 |
